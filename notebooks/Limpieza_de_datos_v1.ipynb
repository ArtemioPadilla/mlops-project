{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBLq6bvdxDpy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ================================\n",
        "# 1. DataLoader\n",
        "# ================================\n",
        "class DataLoader:\n",
        "    def load_csv(self, path):\n",
        "        return pd.read_csv(path)\n",
        "\n",
        "    def save_csv(self, df, path):\n",
        "        df.to_csv(path, index=False)\n",
        "        print(f\"üíæ Guardado en {path} (shape={df.shape})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XZp5-Z3DxTI8"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 2. DataCleaner\n",
        "# ================================\n",
        "class DataCleaner:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def filter_expected_columns(self, expected_cols):\n",
        "        extra = [c for c in self.df.columns if c not in expected_cols]\n",
        "        missing = [c for c in expected_cols if c not in self.df.columns]\n",
        "        if extra: print(\"‚ö†Ô∏è Extras ignoradas:\", extra)\n",
        "        if missing: print(\"‚ö†Ô∏è Faltan columnas:\", missing)\n",
        "        self.df = self.df[[c for c in expected_cols if c in self.df.columns]]\n",
        "        return self\n",
        "\n",
        "    def force_numeric(self, exclude=[\"url\"]):\n",
        "        for c in self.df.columns:\n",
        "            if c in exclude:\n",
        "                continue\n",
        "            if self.df[c].dtype == \"O\":\n",
        "                self.df[c] = (\n",
        "                    self.df[c].astype(str)\n",
        "                    .str.replace(\",\", \".\", regex=False)\n",
        "                    .replace({\"nan\": np.nan, \"None\": np.nan, \"\": np.nan})\n",
        "                )\n",
        "            self.df[c] = pd.to_numeric(self.df[c], errors=\"coerce\")\n",
        "        return self\n",
        "\n",
        "    def apply_business_rules(self):\n",
        "        # ejemplo timedelta\n",
        "        if \"timedelta\" in self.df:\n",
        "            self.df[\"timedelta\"] = self.df[\"timedelta\"].clip(0, 731)\n",
        "        # clip proporciones\n",
        "        clip_01 = [\"n_unique_tokens\", \"global_subjectivity\"]\n",
        "        for c in clip_01:\n",
        "            if c in self.df:\n",
        "                self.df[c] = self.df[c].clip(0, 1)\n",
        "        return self\n",
        "\n",
        "    def winsorize_columns(self, exclude=set()):\n",
        "        def winsorize(s, low=0.01, high=0.99):\n",
        "            if s.notna().sum() == 0: return s\n",
        "            ql, qh = s.quantile(low), s.quantile(high)\n",
        "            return s.clip(ql, qh)\n",
        "        num_cols = [c for c in self.df.select_dtypes(include=[np.number]).columns if c not in exclude]\n",
        "        for c in num_cols:\n",
        "            self.df[c] = winsorize(self.df[c])\n",
        "        return self\n",
        "\n",
        "    def normalize_lda(self, lda_cols=None):\n",
        "        if not lda_cols: return self\n",
        "        lda_cols = [c for c in lda_cols if c in self.df]\n",
        "        if lda_cols:\n",
        "            s = self.df[lda_cols].sum(axis=1)\n",
        "            mask = s > 0\n",
        "            self.df.loc[mask, lda_cols] = self.df.loc[mask, lda_cols].div(s[mask], axis=0)\n",
        "        return self\n",
        "\n",
        "    def clean_primary_key(self, key=\"url\"):\n",
        "        self.df = self.df[self.df[key].notna() & (self.df[key] != \"\")]\n",
        "        self.df[key] = self.df[key].astype(str).str.strip().str.lower()\n",
        "        self.df = self.df[self.df[key].str.startswith(\"http\", na=False)]\n",
        "        return self\n",
        "\n",
        "    def impute_missing_values(self):\n",
        "        for col in self.df.columns[1:]:\n",
        "            skew = self.df[col].skew()\n",
        "            if -1 < skew < 1:\n",
        "                val = self.df[col].mean()\n",
        "                self.df[col] = self.df[col].fillna(val)\n",
        "            else:\n",
        "                val = self.df[col].median()\n",
        "                self.df[col] = self.df[col].fillna(val)\n",
        "        return self\n",
        "\n",
        "    def get_df(self):\n",
        "        return self.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pvgiffiBxapt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ==============================\n",
        "# 3. DataComparator\n",
        "# ==============================\n",
        "class DataComparator:\n",
        "    def __init__(self, orig, clean):\n",
        "        self.orig = orig\n",
        "        self.clean = clean\n",
        "        self.report = pd.DataFrame()  # evita problemas con None\n",
        "\n",
        "    def compare_stats(self):\n",
        "        \"\"\"Calcula estad√≠sticas descriptivas (media y mediana).\"\"\"\n",
        "        self.report = pd.DataFrame({\n",
        "            \"mean_orig\": self.orig.mean(numeric_only=True),\n",
        "            \"mean_clean\": self.clean.mean(numeric_only=True),\n",
        "            \"median_orig\": self.orig.median(numeric_only=True),\n",
        "            \"median_clean\": self.clean.median(numeric_only=True)\n",
        "        })\n",
        "        return self\n",
        "\n",
        "    def add_differences(self):\n",
        "        \"\"\"Agrega diferencias absolutas entre original y limpio.\"\"\"\n",
        "        if self.report.empty:\n",
        "            raise ValueError(\"Primero ejecuta compare_stats() antes de add_differences().\")\n",
        "        self.report[\"diff_mean\"] = (self.report[\"mean_clean\"] - self.report[\"mean_orig\"]).abs()\n",
        "        self.report[\"diff_median\"] = (self.report[\"median_clean\"] - self.report[\"median_orig\"]).abs()\n",
        "        return self\n",
        "\n",
        "    def missing_values_ratio(self):\n",
        "        \"\"\"Calcula proporci√≥n de valores faltantes en %.\"\"\"\n",
        "        self.report[\"missing_orig_%\"] = (self.orig.isna().sum() / len(self.orig)) * 100\n",
        "        self.report[\"missing_clean_%\"] = (self.clean.isna().sum() / len(self.clean)) * 100\n",
        "        return self\n",
        "\n",
        "    def export_report(self, path):\n",
        "        \"\"\"Exporta el reporte a CSV.\"\"\"\n",
        "        if self.report.empty:\n",
        "            raise ValueError(\"No hay reporte que exportar. Ejecuta los m√©todos primero.\")\n",
        "        self.report.to_csv(path, index=False)\n",
        "        print(f\"üìä Reporte exportado a {path}\")\n",
        "        return self.report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "ok0JkFmLxhiK",
        "outputId": "f8b12ee2-6c92-44aa-ad4e-a203509f2806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Columnas extra ignoradas: ['mixed_type_col']\n",
            "üíæ Guardado en online_news_cleaned.csv (shape=(40010, 61))\n",
            "üìä Reporte exportado a comparacion_final.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_orig</th>\n",
              "      <th>mean_clean</th>\n",
              "      <th>median_orig</th>\n",
              "      <th>median_clean</th>\n",
              "      <th>diff_mean</th>\n",
              "      <th>diff_median</th>\n",
              "      <th>missing_orig_%</th>\n",
              "      <th>missing_clean_%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>timedelta</th>\n",
              "      <td>354.530471</td>\n",
              "      <td>357.429169</td>\n",
              "      <td>339.000000</td>\n",
              "      <td>347.000000</td>\n",
              "      <td>2.898698</td>\n",
              "      <td>8.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_tokens_title</th>\n",
              "      <td>10.398749</td>\n",
              "      <td>11.537167</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.138418</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_tokens_content</th>\n",
              "      <td>546.514731</td>\n",
              "      <td>551.298060</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>413.000000</td>\n",
              "      <td>4.783329</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <td>0.548216</td>\n",
              "      <td>0.535094</td>\n",
              "      <td>0.539226</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.013122</td>\n",
              "      <td>7.640113e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <td>0.996469</td>\n",
              "      <td>1.129708</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133240</td>\n",
              "      <td>4.799994e-11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <td>0.689175</td>\n",
              "      <td>0.730050</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.691743</td>\n",
              "      <td>0.040875</td>\n",
              "      <td>1.266930e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_hrefs</th>\n",
              "      <td>10.883690</td>\n",
              "      <td>11.870682</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.986992</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <td>3.293638</td>\n",
              "      <td>3.579641</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.286002</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_imgs</th>\n",
              "      <td>4.544143</td>\n",
              "      <td>4.918595</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.374452</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_videos</th>\n",
              "      <td>1.249874</td>\n",
              "      <td>1.334141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.084268</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_token_length</th>\n",
              "      <td>4.548239</td>\n",
              "      <td>5.271088</td>\n",
              "      <td>4.664082</td>\n",
              "      <td>4.667170</td>\n",
              "      <td>0.722849</td>\n",
              "      <td>3.087656e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_keywords</th>\n",
              "      <td>7.223767</td>\n",
              "      <td>7.251389</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.027622</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_channel_is_lifestyle</th>\n",
              "      <td>0.052946</td>\n",
              "      <td>0.056786</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_channel_is_entertainment</th>\n",
              "      <td>0.178009</td>\n",
              "      <td>0.179330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001321</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_channel_is_bus</th>\n",
              "      <td>0.157855</td>\n",
              "      <td>0.159885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002030</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                mean_orig  mean_clean  median_orig  \\\n",
              "timedelta                      354.530471  357.429169   339.000000   \n",
              "n_tokens_title                  10.398749   11.537167    10.000000   \n",
              "n_tokens_content               546.514731  551.298060   409.000000   \n",
              "n_unique_tokens                  0.548216    0.535094     0.539226   \n",
              "n_non_stop_words                 0.996469    1.129708     1.000000   \n",
              "n_non_stop_unique_tokens         0.689175    0.730050     0.690476   \n",
              "num_hrefs                       10.883690   11.870682     8.000000   \n",
              "num_self_hrefs                   3.293638    3.579641     3.000000   \n",
              "num_imgs                         4.544143    4.918595     1.000000   \n",
              "num_videos                       1.249874    1.334141     0.000000   \n",
              "average_token_length             4.548239    5.271088     4.664082   \n",
              "num_keywords                     7.223767    7.251389     7.000000   \n",
              "data_channel_is_lifestyle        0.052946    0.056786     0.000000   \n",
              "data_channel_is_entertainment    0.178009    0.179330     0.000000   \n",
              "data_channel_is_bus              0.157855    0.159885     0.000000   \n",
              "\n",
              "                               median_clean  diff_mean   diff_median  \\\n",
              "timedelta                        347.000000   2.898698  8.000000e+00   \n",
              "n_tokens_title                    10.000000   1.138418  0.000000e+00   \n",
              "n_tokens_content                 413.000000   4.783329  4.000000e+00   \n",
              "n_unique_tokens                    0.538462   0.013122  7.640113e-04   \n",
              "n_non_stop_words                   1.000000   0.133240  4.799994e-11   \n",
              "n_non_stop_unique_tokens           0.691743   0.040875  1.266930e-03   \n",
              "num_hrefs                          8.000000   0.986992  0.000000e+00   \n",
              "num_self_hrefs                     3.000000   0.286002  0.000000e+00   \n",
              "num_imgs                           1.000000   0.374452  0.000000e+00   \n",
              "num_videos                         0.000000   0.084268  0.000000e+00   \n",
              "average_token_length               4.667170   0.722849  3.087656e-03   \n",
              "num_keywords                       7.000000   0.027622  0.000000e+00   \n",
              "data_channel_is_lifestyle          0.000000   0.003840  0.000000e+00   \n",
              "data_channel_is_entertainment      0.000000   0.001321  0.000000e+00   \n",
              "data_channel_is_bus                0.000000   0.002030  0.000000e+00   \n",
              "\n",
              "                               missing_orig_%  missing_clean_%  \n",
              "timedelta                                 0.0              0.0  \n",
              "n_tokens_title                            0.0              0.0  \n",
              "n_tokens_content                          0.0              0.0  \n",
              "n_unique_tokens                           0.0              0.0  \n",
              "n_non_stop_words                          0.0              0.0  \n",
              "n_non_stop_unique_tokens                  0.0              0.0  \n",
              "num_hrefs                                 0.0              0.0  \n",
              "num_self_hrefs                            0.0              0.0  \n",
              "num_imgs                                  0.0              0.0  \n",
              "num_videos                                0.0              0.0  \n",
              "average_token_length                      0.0              0.0  \n",
              "num_keywords                              0.0              0.0  \n",
              "data_channel_is_lifestyle                 0.0              0.0  \n",
              "data_channel_is_entertainment             0.0              0.0  \n",
              "data_channel_is_bus                       0.0              0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ================================\n",
        "# 4. Ejemplo de uso\n",
        "# ================================\n",
        "if __name__ == \"__main__\":\n",
        "    loader = DataLoader()\n",
        "\n",
        "    # Carga de datos (ajustado a tus archivos en ra√≠z)\n",
        "    orig = loader.load_csv(\"../../Data/online_news_original.csv\")\n",
        "    mod = loader.load_csv(\"../../Data/online_news_modified.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ================================\n",
        "    # Definir columnas esperadas\n",
        "    # ================================\n",
        "    expected_cols = [\n",
        "        \"url\",\"timedelta\",\"n_tokens_title\",\"n_tokens_content\",\"n_unique_tokens\",\n",
        "        \"n_non_stop_words\",\"n_non_stop_unique_tokens\",\"num_hrefs\",\"num_self_hrefs\",\n",
        "        \"num_imgs\",\"num_videos\",\"average_token_length\",\"num_keywords\",\n",
        "        \"data_channel_is_lifestyle\",\"data_channel_is_entertainment\",\"data_channel_is_bus\",\n",
        "        \"data_channel_is_socmed\",\"data_channel_is_tech\",\"data_channel_is_world\",\n",
        "        \"kw_min_min\",\"kw_max_min\",\"kw_avg_min\",\"kw_min_max\",\"kw_max_max\",\"kw_avg_max\",\n",
        "        \"kw_min_avg\",\"kw_max_avg\",\"kw_avg_avg\",\n",
        "        \"self_reference_min_shares\",\"self_reference_max_shares\",\"self_reference_avg_sharess\",\n",
        "        \"weekday_is_monday\",\"weekday_is_tuesday\",\"weekday_is_wednesday\",\"weekday_is_thursday\",\n",
        "        \"weekday_is_friday\",\"weekday_is_saturday\",\"weekday_is_sunday\",\"is_weekend\",\n",
        "        \"LDA_00\",\"LDA_01\",\"LDA_02\",\"LDA_03\",\"LDA_04\",\n",
        "        \"global_subjectivity\",\"global_sentiment_polarity\",\n",
        "        \"global_rate_positive_words\",\"global_rate_negative_words\",\n",
        "        \"rate_positive_words\",\"rate_negative_words\",\n",
        "        \"avg_positive_polarity\",\"min_positive_polarity\",\"max_positive_polarity\",\n",
        "        \"avg_negative_polarity\",\"min_negative_polarity\",\"max_negative_polarity\",\n",
        "        \"title_subjectivity\",\"title_sentiment_polarity\",\n",
        "        \"abs_title_subjectivity\",\"abs_title_sentiment_polarity\",\n",
        "        \"shares\"\n",
        "    ]\n",
        "\n",
        "    # Columnas extra o faltantes\n",
        "    extra_cols = [c for c in mod.columns if c not in expected_cols]\n",
        "    missing_cols = [c for c in expected_cols if c not in mod.columns]\n",
        "\n",
        "    if extra_cols:\n",
        "        print(\"‚ö†Ô∏è Columnas extra ignoradas:\", extra_cols)\n",
        "    if missing_cols:\n",
        "        print(\"‚ö†Ô∏è Columnas esperadas que no encontr√© (seguir√© sin ellas):\", missing_cols)\n",
        "\n",
        "    keep_cols = [c for c in expected_cols if c in mod.columns]\n",
        "    mod = mod[keep_cols]\n",
        "\n",
        "    # ================================\n",
        "    # Limpieza\n",
        "    # ================================\n",
        "    cleaner = DataCleaner(mod)\n",
        "    mod_clean = (cleaner\n",
        "        .filter_expected_columns(expected_cols=keep_cols)\n",
        "        .force_numeric()\n",
        "        .apply_business_rules()\n",
        "        .winsorize_columns()\n",
        "        .normalize_lda([\"LDA_00\", \"LDA_01\", \"LDA_02\", \"LDA_03\", \"LDA_04\"])\n",
        "        .clean_primary_key()\n",
        "        .impute_missing_values()\n",
        "        .get_df())\n",
        "\n",
        "    loader.save_csv(mod_clean, \"online_news_cleaned.csv\")\n",
        "\n",
        "    # ================================\n",
        "    # Comparaci√≥n con original\n",
        "    # ================================\n",
        "    comparator = DataComparator(orig, mod_clean)\n",
        "    report = (comparator\n",
        "        .compare_stats()\n",
        "        .add_differences()\n",
        "        .missing_values_ratio()\n",
        "        .export_report(\"comparacion_final.csv\"))\n",
        "\n",
        "    display(report.head(15))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlops_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
